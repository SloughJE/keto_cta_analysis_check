---
title: "Keto-CTA Study"
subtitle: "An Analysis of the Available Data"
author: "John (The John & Calvin Podcast)"
format:
  revealjs:
    self-contained: true
    theme: [night]
    slide-number: true
    css: styles.css
---




## Incorrect Y-Axis Tick Labels

::: {.columns}

::: {.column width="45%"}


::: {.smaller_table}

**Figure 1B from Study**
:::

::: {.fragment}

![](assets/Figure1B.jpg){width=90% fig-link="https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686"}

:::
:::

::: {.column width="10%"}

:::
::: {.column width="45%"}

::: {.smaller_table}

**Figure 1B from Data**

:::

::: {.fragment}

![](figures/Figure1B.png){width=90%}

:::

:::

::: {.smaller_caption}

Individual Change in Plaque Volume


\(B) The red line represents the median change (0.8%), and the shaded area represents the IQR (0.3%-1.7%).

:::
:::

---

## Incorrect Shading Area

::: {.columns}

::: {.column width="45%"}


::: {.smaller_table}

**Figure 1A from Study**

:::

::: {.fragment}

![](assets/Figure1A.jpg){width=90% fig-link="https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686"}

:::
:::

::: {.column width="10%"}

:::
::: {.column width="45%"}

::: {.smaller_table}

**Figure 1A from Data**

:::

::: {.fragment}

![](figures/Figure1A.png){width=90%}

:::

:::

::: {.smaller_caption}

Individual Change in Plaque Volume


\(A). The red line represents the median change (18.9 mm3), and the shaded area represents the IQR (9.3-47.0 mm3).

:::
:::

---

## Incorrect Y-Axis Tick Labels

::: {.columns}

::: {.column width="45%"}


::: {.smaller_table}

**Figure 2F from Study**

:::

::: {.fragment}

![](assets/Figure2F.jpg){width=90% fig-link="https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686"}

:::
:::

::: {.column width="10%"}

:::
::: {.column width="45%"}

::: {.smaller_table}

**Figure 2F from Data**

:::

::: {.fragment}

![](figures/Figure2F.png){width=90%}

:::

:::

::: {.smaller_caption}

Changes in Total Plaque Score vs Coronary Artery Calcium

\(C, F) Only CAC is associated with changes in NCPV and TPS. The regression line was fitted with the function "lm," which
regresses y~x, and the shaded area represents the standard error. 

:::
:::

---


## Linear Model Assumptions 


::: {.smaller}


4 Simple Linear Regression Assumptions

3 are tested with data

::: {.fragment}

- **Linearity**: between the predictor and the outcome

- **Constant variance** (homoscedasticity) of residuals

- **Normally distributed residuals** 

:::

<br>

::: {.fragment}

These linear assumptions are **quantifiable** and **objectively testable**.

:::
::: {.fragment}

- If the assumptions don’t hold, statistical significance and uncertainty estimates aren’t trustworthy
- Results may be invalid

:::
:::

::: {.notes}

- Linearity: on average, the relationship between the predictor and the outcome is a straight line

If the true pattern is curved, the slope summarizes the wrong thing and can misstate direction and size.

- Independence of errors

Dependence makes uncertainty estimates too small or too large.

- Constant variance (homoskedasticity)

If the spread grows or shrinks, standard errors and p-values from the basic model are mis-calibrated.

- Normally Distributed Residuals (errors) (mainly for small samples): error terms follow normal distribution.

The usual t-tests and confidence intervals rely on this; strong departures undermine those calculations.


- No exact collinearity (relevant in multivariable settings): predictors aren’t exact copies of each other.


:::


---


![](assets/Table3_caption.png){width=90%  fig-align="center"}

---

![](assets/Table3_caption_highlight.png){width=90%  fig-align="center"}

---

## Violations

::: {.smaller_table}

> ["all linear model assumptions were corroborated with the R function `performance::check_model`."](https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686)
>
> \- *Direct quote from the study*

:::

::: {.smaller2}
::: {.fragment}

Actual Assumption Tests

:::
:::

::: {.fragment}

```{r echo=FALSE, message=FALSE, results='asis'}

source("code/linear_models.R")

gt_tbl

```

:::

::: {.smaller2}


::: {.fragment}

Objective tests show all 4 models failed at least 2 tests.

:::
:::

::: {.notes}

- RESET test for linearity

- Breusch–Pagan test for Constant Variance (heterskedasticity)

- Shapiro–Wilk test for normal residuals

Calling residual-plot evaluation “subjective” is **misleading.**
Visual checks are interpretive, but these assumptions are **objectively quantifiably** testable

Robust Linear Regression mainly down-weights outliers

It does not deal with non-linearity, heteroskedasticity and non-normality of residuals (directly, it can help sometimes...but)


:::

---

### Response from Authors


::: {.smaller2}

> ["The validity of the regression models is also questionable. Despite claims of meeting assumptions, variables were reported using medians, suggesting non-normal distributions. Visual inspection of scatter plots shows clustering and no clear linear trends. Robust or nonparametric methods might have been more appropriate, and model diagnostics would improve transparency."](https://www.jacc.org/doi/10.1016/j.jacadv.2025.101861)
>
> \- *quote from letter to the editor*

::: {.fragment}

> ["we are aware of the relevance of linear assumptions to obtain accurate estimators. Because residual plot evaluation can also be subjective, we followed their suggestion and reran all models with robust linear regression (using the `MASS::rlm` function in R version 4.4.3 [R Foundation]). While, as expected, there were small differences with the published estimates, all models using robust regression were consistent with what was reported."](https://www.jacc.org/doi/10.1016/j.jacadv.2025.101862)
>
> \- *quote from the reply to a letter to the editor*

:::
:::

---

### Subjective Assumptions


::: {.smaller}

::: {.fragment}

- Calling residual-plot evaluation "subjective" is **misleading.**

- Visual checks are interpretive, but these linear assumptions are **quantifiable** and **objectively testable**.

:::
::: {.fragment}

- Robust Linear Regression mainly just down-weights outliers.

:::
::: {.fragment}

- Does not deal with non-linearity, heteroskedasticity and non-normality of residuals.

:::

:::

::: {.notes}

RLM can sometimes help a bit with non-normality but depends.

:::


---


![](figures/diagnostics/check__NCPV_CAC_bl.png){width=100%  fig-align="center"}


---

### Conclusions vs Actual Reported Model

::: {.smaller2}

> "**CONCLUSIONS** In lean metabolically healthy people on KD, neither total exposure nor changes in baseline levels of ApoB and LDL-C were associated with changes in plaque."

:::

::: {.smaller_table}

<br>

::: {.fragment}


| **Abstract claim component**  | **Model**                     | **Model reported**                     |
| ----------------------------- | ----------------------------- | -------------------------------------- |
| Δ-plaque vs LDL-C exposure    | Δ-NCPV \~ LDL-C exposure     | Not reported                           |
| Δ-plaque vs LDL-C baseline    | Δ-NCPV \~ LDL-C baseline     | Not reported                           |
| Δ-plaque vs ΔLDL-C            | Δ-NCPV \~ ΔLDL-C             | Not reported                           |
| Δ-plaque vs ApoB exposure     | Δ-NCPV \~ ApoB exposure      | Not reported                           |
| Δ-plaque vs ApoB baseline     | Δ-NCPV \~ ΔApoB              | **Reported**                           |
| Δ-plaque vs ΔApoB             | Δ-NCPV \~ ΔApoB              | **Reported**                           |
| N/A                           | NCPV_final \~ LDL-C exposure | **Reported** (NCPV\_final, PAV\_final) |

:::
:::

---

### No TPS Model Results

::: {.smaller_table}

> "**Results** Neither change in ApoB ..., baseline ApoB, nor total LDL-C exposure ... were associated with the change in noncalcified plaque volume (NCPV) or TPS."

> "Neither … change in ApoB nor the ApoB level ... were associated ... with **TPS** (Figures 2D and 2E, **Table 3**)." - "changes in and baseline levels of ApoB were not associated with changes in NCPV or TPS"

<br>

:::

::: {.smaller2}

::: {.fragment}

Figures 2D–2F are Δ-TPS (outcome) panels (vs ΔApoB, ApoB, CAC_bl)

:::

<br>

::: {.fragment}

Table 3 has no Δ-TPS models

No Δ-TPS ~ LDL-C exposure models or results anywhere.

:::
:::

---


### Lifetime LDL-C Exposure Calculation

::: {.smaller_table}

> "LDL-C exposure on a KD was calculated by sum- ming the products of the reported days on a KD prior to study commencement and baseline LDL-C on a KD plus the study follow-up days by their final LDL-C."



$$
\text{LDL-C}_{\text{exp}}
=
Days_{\text{KD}}\cdot LDL_{\text{baseline}}
\;+\;
Days_{\text{follow-up}}\cdot LDL_{\text{final}}
$$

<br>

:::
::: {.smaller2}

::: {.fragment}

- one baseline value for all pre-study KD time and one final value for all follow-up is a coarse simplification
- standard AUC/time-weighted approach (need multiple measurements)
- limitation due to resources
- relies on recall of KD start

:::
:::

---

### Lifetime LDL-C Exposure Calculation

::: {.smaller_table}

> "LDL-C exposure on a KD was calculated by summing the products of the reported days on a KD prior to study commencement and baseline LDL-C on a KD plus the study follow-up days by their final LDL-C."



$$
\text{LDL-C}_{\text{exp}}
=
Days_{\text{KD}}\cdot LDL_{\text{baseline}}
\;+\;
Days_{\text{follow-up}}\cdot LDL_{\text{final}}
$$


> "Estimated lifelong LDL-C additionally included the product of age upon commencing a KD and pre-KD LDL-C."


$$
\text{Life-LDL-C}_{\text{exp}}
=
Days_{\text{KD}}\cdot LDL_{\text{baseline}}
\;+\;
Days_{\text{follow-up}}\cdot LDL_{\text{final}}
\;+\;
\boldsymbol{\big( Age_{\text{at-KD-start}}\cdot LDL_{\text{pre-KD}} \big)}
$$

::: {.fragment}

- **This equation is nonsensical. It is invalid.**

:::
::: {.fragment}
- It adds days and age together. It's like adding miles and inches.
- pre-KD term is down-scaled by ~365× relative to the day-based terms.
- any associations with outcomes are dominated by keto diet exposure.
- if they did convert age, "lifetime" exposure just reflects how old someone was at KD

:::
:::

---

### Age "mediation" analysis


![](assets/Age_mediation_bp.png){style="width:60%; height:auto !important;"}

::: {.smaller_caption}

> "Estimated lifetime LDL-C exposure was only a significant predictor of final NCPV in the univariable analysis but lost significance when age was included as a covariate (Table 3). Both age and lifetime LDL-C exposure lost significance when baseline CAC was included in the model (Table 3)."

:::

::: {.smaller_table}

**This is not a "mediation" analysis**. A mediation analysis:

::: {.fragment}

- tests how an exposure affects an outcome through a middle step (the *mediator*)
- estimates an indirect effect (through the mediator) and a direct effect (everything else).
- requires a pre-specified pathway and proper statistical testing (usually with CIs or bootstraps).

::: {.fragment}

This isn't mediation analysis

- No indirect effect was estimated or tested.
- Age can’t be a mediator of LDL exposure (age isn’t caused by LDL); it’s a confounder.
- They only compared p-values after adding variables.

:::
:::
:::

::: {.notes}


Exposure (E): lifetime LDL-C exposure
Mediator (M): baseline CAC (CAC_bl)
Outcome (Y): final NCPV
Confounder (A): age (affects E, M, and Y)

- The mediated/indirect path you’d test is: E → M → Y (LDL exposure → baseline CAC → final NCPV).
- When you include M = baseline CAC in the model, you block that E → M → Y path and estimate only the direct effect of E on Y (the E → Y arrow not going through M).

So “Adding baseline CAC blocks the pathway → tests only the direct effect” means: conditioning on baseline CAC removes the indirect route through CAC, leaving only the unmediated E → Y association to be estimated.


What mediation is (A → C through B):

Specify roles: Exposure (A), Mediator (B), Outcome (C).

Fit two models:

B ~ A (+ confounders) → path a

C ~ A + B (+ confounders) → paths b, c′

Report the indirect effect (a×b) with CIs (usually bootstrapped). State assumptions.

Only shows outcome regressions (NCPV_final ~ Age, then + Life-LDL-C_exp, then + CAC_bl).

No mediator model, no indirect effect, no CIs.

The “mediator” (Life-LDL-C_exp) is partly built from Age and mixes units → mathematical coupling; any drop in the Age coefficient can be mechanical.


:::

---

### Age "mediation" analysis


![](assets/Age_mediation_bp.png){style="width:60%; height:auto !important;"}

::: {.smaller_caption}

> "Estimated lifetime LDL-C exposure was only a significant predictor of final NCPV in the univariable analysis but lost significance when age was included as a covariate (Table 3). Both age and lifetime LDL-C exposure lost significance when baseline CAC was included in the model (Table 3)."

:::

::: {.smaller_table}

They ran (reported) three regressions in sequence.

::: {.fragment}

Conclusion: after adjusting for baseline CAC, neither age nor lifetime LDL-C predicts NCPV_final.

:::
::: {.fragment}

- CAC explains the association; age / lifetime LDL-exposure don’t matter.

:::
::: {.fragment}

Changes in p-values come from collinearity due to Age being embedded in lifetime LDL-C exposure.

Age is a confounder/proxy for exposure duration, not a mediator.

<br> 

:::
::: {.fragment}

**They did NOT report `NCPV_final ~ lifetime LDL-C exposure` model results.**

:::
:::

::: {.notes}

they actually did a stepwise covariate adjustment on highly collinear variables and then over-interpreted p-value changes.

“loss of significance” doesn’t show that LDL or Age don’t matter; it shows the model is not set up to answer the mediation/mechanism question.


Intended pathway?: lifetime LDL-C → baseline CAC → NCPV_final.

Age affects all variables.


The “mediator” (Life-LDL-C_exp) is partly built from Age and mixes units → mathematical coupling; any drop in the Age coefficient can be mechanical.


:::

---

### "Sensitivity" Analysis

::: {.smaller_table}

> "Sensitivity analyses on participants with >80% of bHB measurements above 0.3 mmol/L (Supplemental Tables 2 to 4) and with high calculated 10-year cardiovascular risk showed similar results to those just reported (Supplemental Table 5)."

:::

::: {.smaller2}

::: {.fragment}

This is **not** a sensitivity analysis. This is a subgroup analysis. 
:::
::: {.fragment}

**Sensitivity analysis**: demonstrate robustness of conclusions to reasonable alternative assumptions or analytic choices

:::
::: {.fragment}

**Subgroup analysis**: assess differences of effects across subsets of the dataset (e.g., high vs low adherence; low vs high baseline risk).


Properly, this is tested with interaction terms in the full sample, not by splitting the data, running the exact same models and eyeballing p-values.

:::
:::


---

### Bayes Factor R-scale

::: {.smaller_table}

> "Bayes factors were calculated...with default settings and an `~ rscale value of 0.8` to contrast a moderately informative prior with a conservative distribution width (to allow for potential large effect sizes) due to the well-documented association between ApoB changes and coronary plaque changes."

:::

::: {.smaller2}

::: {.fragment}

Calling 0.8 "moderately informative" is inaccurate.

:::
::: {.fragment}

[R package docs](https://search.r-project.org/CRAN/refmans/BayesFactor/html/regressionBF.html): **"medium", "wide", "ultrawide" = 0.354, 0.5, 0.707**  

:::
::: {.fragment}

- `rscaleCont = 0.8` is **wider than “ultrawide”** → a **very diffuse** prior that places substantial mass on **very large** effects  
- No reported **prior-sensitivity** to alternative r-scales  
- Same r-scale apparently used for **all models**, no justification.

:::
:::

::: {.smaller_table}
::: {.fragment}

**Fixed description**:
:::

::: {.fragment}

"We used a very wide prior on coefficients (`rscale = 0.8`, wider than the package’s "ultrawide"), which places substantial prior mass on very large effects. This diffuse prior penalizes small-to-moderate effects, requiring substantially stronger evidence than under the ‘wide’ or ‘medium’ defaults to support them."

:::

:::


---

### Univariable change-score models as primary evidence


---

### Preprint vs Published Version

Title is now: Longitudinal Data From the KETO-CTA Study
Plaque Predicts Plaque, ApoB Does Not

Find and replace 'begets' with 'predicts'.

"Most participants presented with stable NCPV (Figures 1A and 1B), with 1 participant exhibiting a decrease in NCPV"

That interpretation of Figures 1A and 1B was removed and replaced with:

"The median change in NCPV was 18.9 mm3 (IQR: 9.3-47.0 mm3) and the median change in PAV was 0.8% (IQR: 0.3%-1.7%)."

Table 1 median (Q1–Q3) PAV at baseline changed from 1.25% (0.5–3.6) in the preprint to 1.6% (0.5–4.9


The two violations you keep seeing—non-normality and heteroskedasticity—are largely driven by the outcome’s distribution (ΔNCPV) and its mean–variance pattern. Swapping predictors (e.g., APOB vs CAC) usually won’t fix those. So it’s likely most univariable Δ models would show the same two problems.


- 2 assumption violations:

The simple linear model breaks two key rules: the residuals aren’t normally distributed and their spread changes with 
x (heteroskedasticity).

The estimated slope (the “trend”) can still be a good average summary of how y changes with x.

But the usual p-values/confidence intervals from ordinary least squares (OLS) can’t be trusted because the standard error formula is wrong under heteroskedasticity, and non-normality hurts small-sample tests.
If your OLS p-value < 0.05: treat it as suggestive, not definitive. Recompute using heteroskedasticity-robust or bootstrap methods. It may stay significant—or it may not.
If your OLS p-value ≥ 0.05: you can’t conclude “no association.” The test might be too noisy or mis-calibrated. Recheck with robust/bootstrapped standard errors and report the effect size with a confidence interval.

the conventional OLS standard errors, t-tests, and CIs are invalid with heteroskedasticity; non-normality further invalidates small-sample t-inference.

- 3 assumption violation (linearity)

In plain terms
The model breaks three core assumptions: residuals aren’t normal, their spread changes with  x, and the relationship isn’t actually linear.
Because of the changing spread, the usual p-values/intervals are mis-calibrated (they can be too small or too big).
Because the relationship isn’t linear, the reported “slope” isn’t a clear effect; it’s just a weighted average of a curved pattern. Its size—or even its sign—may not reflect the true relationship.
If the reported OLS p-value < 0.05:
“This suggests a non-zero average linear trend, but inference is mis-calibrated and the effect has no clear meaning under a misspecified (nonlinear) model. The ‘significance’ may be an artifact.”
If the reported OLS p-value ≥ 0.05:
“This is a non-result from a mis-calibrated, misspecified model. It does not justify concluding ‘no association,’ and it may mask real patterns due to the nonlinear form and changing variance.”

Interpretation of reported results:
p < 0.05: Evidence only for a non-zero projected linear component under misspecification; inference is mis-sized and the estimand lacks a clear causal/functional meaning.
p ≥ 0.05: Absence of evidence from a misspecified, mis-sized test; it does not speak to the presence or absence of a true association.


### Assumptions of linear model
Assumptions of a linear model (and why they matter)
Linearity of the mean: the average outcome changes in a straight-line way with the predictor.
Why it matters: If the true pattern is curved, the slope summarizes the wrong thing and can misstate direction and size.

Independence of errors: observations don’t carry leftover information about each other (no autocorrelation/clustering).
Why it matters: Dependence makes uncertainty estimates too small or too large.

Constant variance (homoskedasticity): the scatter of errors is roughly the same across the predictor.
Why it matters: If the spread grows or shrinks, standard errors and p-values from the basic model are mis-calibrated.

Approximately normal errors (mainly for small samples): error terms are roughly bell-shaped.
Why it matters: The usual t-tests and confidence intervals rely on this; strong departures undermine those calculations.

Exogeneity / no systematic bias: on average, errors are unrelated to the predictor (no omitted confounders correlated with 
x).
Why it matters: Violations bias the slope itself, not just its uncertainty.

No exact collinearity (relevant in multivariable settings): predictors aren’t exact copies of each other.
Why it matters: Otherwise the model can’t isolate individual effects. (Not an issue in a single-predictor model.)


The study’s univariable ‘ΔNCPV ~ APOB’ analysis is not decisive. The appropriate test is APOB’s partial association in a follow-up model that controls for baseline NCPV (and age/sex). Only 
H
0
 ⁣
:
β
APOB
=
0
H 
0
​	
 :β 
APOB
​	
 =0 in follow-up ~ baseline + APOB + covariates addresses whether APOB is associated with follow-up independent of baseline.
 
The reported null does not address whether APOB is associated with follow-up conditional on baseline, age, and sex, which is the clinically relevant estimand.
